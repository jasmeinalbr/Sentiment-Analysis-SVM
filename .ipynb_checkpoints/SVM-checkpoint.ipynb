{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import _pickle as cPickle\n",
    "from scipy.io import loadmat\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import learning_curve  # Perbaikan\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>India is developing countries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Da Vinci Code book is just awesome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>this was the first clive cussler i've ever rea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked                                               text\n",
       "0      1                      India is developing countries\n",
       "1      1            The Da Vinci Code book is just awesome.\n",
       "2      1  this was the first clive cussler i've ever rea..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Training.txt\", sep=\"\\t\", names=['liked', 'text'], encoding=\"utf-8\")\n",
    "df.head(3)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6931\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liked</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2975</td>\n",
       "      <td>559</td>\n",
       "      <td>I hate Harry Potter.</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3956</td>\n",
       "      <td>744</td>\n",
       "      <td>I love Harry Potter.</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text                                  \n",
       "      count unique                   top freq\n",
       "liked                                        \n",
       "0      2975    559  I hate Harry Potter.   85\n",
       "1      3956    744  I love Harry Potter.  167"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('liked').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens(review):\n",
    "    return TextBlob(review).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [India, is, developing, countries]\n",
       "1         [The, Da, Vinci, Code, book, is, just, awesome]\n",
       "2       [this, was, the, first, clive, cussler, i, 've...\n",
       "3                [i, liked, the, Da, Vinci, Code, a, lot]\n",
       "4                [i, liked, the, Da, Vinci, Code, a, lot]\n",
       "                              ...                        \n",
       "6926                   [Brokeback, Mountain, was, boring]\n",
       "6927    [So, Brokeback, Mountain, was, really, depress...\n",
       "6928    [As, I, sit, here, watching, the, MTV, Movie, ...\n",
       "6929    [Ok, brokeback, mountain, is, such, a, horribl...\n",
       "6930    [Oh, and, Brokeback, Mountain, was, a, terribl...\n",
       "Name: text, Length: 6931, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.apply(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ready', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('a', 'DT'),\n",
       " ('good', 'JJ'),\n",
       " ('movie', 'NN')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"ready was not a good movie\").tags\n",
    "# list of (word, POS) pairs\n",
    "#nltk.help.upenn_tagset('JJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     [india, is, developing, country]\n",
       "1      [the, da, vinci, code, book, is, just, awesome]\n",
       "2    [this, wa, the, first, clive, cussler, i, 've,...\n",
       "3             [i, liked, the, da, vinci, code, a, lot]\n",
       "4             [i, liked, the, da, vinci, code, a, lot]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_into_lemmas(review):\n",
    "    wordss = TextBlob(review.lower()).words\n",
    "    # for each word, take its \"base form\" = lemma \n",
    "    return [word.lemma for word in wordss]\n",
    "\n",
    "df.text.head().apply(split_into_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     [india, is, developing, country]\n",
       "1      [the, da, vinci, code, book, is, just, awesome]\n",
       "2    [this, wa, the, first, clive, cussler, i, 've,...\n",
       "3             [i, liked, the, da, vinci, code, a, lot]\n",
       "4             [i, liked, the, da, vinci, code, a, lot]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_into(review):\n",
    "    words = TextBlob(review.lower()).words\n",
    "    # for each word, take its \"base form\" = lemma \n",
    "    return [word.lemmatize() for word in words]\n",
    "df.text.head().apply(split_into)\n",
    "\n",
    "#df.text.head().apply(lemman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2114\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(df['text'])\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#review1=df['text'][3]\n",
    "#print(review1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bow1=bow_transformer.transform([review1])\n",
    "#print(bow1)\n",
    "#bow1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code-other\n"
     ]
    }
   ],
   "source": [
    "print(bow_transformer.get_feature_names_out()[372])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (6931, 2114)\n",
      "number of non-zeros: 71297\n",
      "sparsity: 7129700.00%\n"
     ]
    }
   ],
   "source": [
    "review_bow = bow_transformer.transform(df['text'])\n",
    "print( 'sparse matrix shape:', review_bow.shape)\n",
    "print('number of non-zeros:', review_bow.nnz) #learn this\n",
    "print( 'sparsity: %.2f%%' % (100.0 * review_bow.nnz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#operators=set(('no','not'))\n",
    "#stopset=set(stopwords.words('english'))-operators\n",
    "#vectorizer=TfidfVectorizer(use_idf=True,lowercase=True,strip_accents='ascii',stop_words=stopset)\n",
    "#stopset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rr=np.array([review])\n",
    "tfidf_transformer =TfidfTransformer().fit(review_bow)\n",
    "#print(tfidf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6931, 2114)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_tfidf = tfidf_transformer.transform(review_bow)\n",
    "review_tfidf.shape\n",
    "#print(x)\n",
    "#print(y)\n",
    "#review_tfidf[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, liked_train, liked_test = train_test_split(df['text'], df['liked'], test_size=0.2)\n",
    "#print(len(text_train), len(text_test), len(text_train) + len(text_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svm = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=split_into_lemmas)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', SVC()),  # <== change here\n",
    "])\n",
    "\n",
    "# pipeline parameters to automatically explore and tune\n",
    "param_svm = [\n",
    "  {'classifier__C': [1, 10, 100, 1000], 'classifier__kernel': ['linear']},\n",
    "  {'classifier__C': [1, 10, 100, 1000], 'classifier__gamma': [0.001, 0.0001], 'classifier__kernel': ['rbf']},\n",
    "]\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    pipeline_svm,\n",
    "    param_grid=param_svm,\n",
    "    refit=True,  # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,  # number of cores to use for parallelization; -1 for \"all cores\"\n",
    "    scoring='accuracy',#optimizing\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.37 s, sys: 293 ms, total: 2.66 s\n",
      "Wall time: 1min 45s\n",
      "{'mean_fit_time': array([9.09090958, 2.93430772, 3.20370569, 3.1019588 , 5.59794369,\n",
      "       5.96438861, 4.25880141, 5.16540484, 3.24390802, 5.42156463,\n",
      "       4.79177933, 3.30473046]), 'std_fit_time': array([3.12433379, 0.16452944, 0.07765985, 0.11513414, 0.45016625,\n",
      "       0.59442541, 0.0730408 , 0.11034164, 0.20950943, 1.75385986,\n",
      "       1.70848039, 0.37657682]), 'mean_score_time': array([0.87315745, 0.74450302, 0.73311343, 0.74109883, 1.13803525,\n",
      "       1.11629019, 1.06905699, 1.28852324, 0.78916841, 1.4451364 ,\n",
      "       0.93111105, 0.74683928]), 'std_score_time': array([0.07218352, 0.02227658, 0.03062289, 0.0268775 , 0.01754715,\n",
      "       0.0152506 , 0.05287688, 0.10290547, 0.02681891, 0.32831569,\n",
      "       0.39309449, 0.15863583]), 'param_classifier__C': masked_array(data=[1, 10, 100, 1000, 1, 1, 10, 10, 100, 100, 1000, 1000],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value=999999), 'param_classifier__kernel': masked_array(data=['linear', 'linear', 'linear', 'linear', 'rbf', 'rbf',\n",
      "                   'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__gamma': masked_array(data=[--, --, --, --, 0.001, 0.0001, 0.001, 0.0001, 0.001,\n",
      "                   0.0001, 0.001, 0.0001],\n",
      "             mask=[ True,  True,  True,  True, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value=1e+20), 'params': [{'classifier__C': 1, 'classifier__kernel': 'linear'}, {'classifier__C': 10, 'classifier__kernel': 'linear'}, {'classifier__C': 100, 'classifier__kernel': 'linear'}, {'classifier__C': 1000, 'classifier__kernel': 'linear'}, {'classifier__C': 1, 'classifier__gamma': 0.001, 'classifier__kernel': 'rbf'}, {'classifier__C': 1, 'classifier__gamma': 0.0001, 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 0.001, 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 0.0001, 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 0.001, 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 0.0001, 'classifier__kernel': 'rbf'}, {'classifier__C': 1000, 'classifier__gamma': 0.001, 'classifier__kernel': 'rbf'}, {'classifier__C': 1000, 'classifier__gamma': 0.0001, 'classifier__kernel': 'rbf'}], 'split0_test_score': array([0.99098287, 0.9864743 , 0.9864743 , 0.9864743 , 0.57078449,\n",
      "       0.57078449, 0.9792606 , 0.57078449, 0.98467087, 0.9792606 ,\n",
      "       0.99098287, 0.98467087]), 'split1_test_score': array([0.98917944, 0.98917944, 0.98917944, 0.98917944, 0.57078449,\n",
      "       0.57078449, 0.9657349 , 0.57078449, 0.98376916, 0.9657349 ,\n",
      "       0.99008115, 0.98376916]), 'split2_test_score': array([0.99278629, 0.99458972, 0.99458972, 0.99458972, 0.57078449,\n",
      "       0.57078449, 0.97565374, 0.57078449, 0.98467087, 0.97565374,\n",
      "       0.99368801, 0.98467087]), 'split3_test_score': array([0.99098287, 0.99458972, 0.99458972, 0.99458972, 0.56988278,\n",
      "       0.56988278, 0.9729486 , 0.56988278, 0.98827773, 0.9729486 ,\n",
      "       0.99098287, 0.98827773]), 'split4_test_score': array([0.99277978, 0.99368231, 0.99368231, 0.99368231, 0.57039711,\n",
      "       0.57039711, 0.97743682, 0.57039711, 0.99277978, 0.97743682,\n",
      "       0.99368231, 0.99277978]), 'mean_test_score': array([0.99134225, 0.9917031 , 0.9917031 , 0.9917031 , 0.57052667,\n",
      "       0.57052667, 0.97420693, 0.57052667, 0.98683368, 0.97420693,\n",
      "       0.99188344, 0.98683368]), 'std_test_score': array([0.00134817, 0.0032952 , 0.0032952 , 0.0032952 , 0.00035519,\n",
      "       0.00035519, 0.00472067, 0.00035519, 0.00335226, 0.00472067,\n",
      "       0.00150749, 0.00335226]), 'rank_test_score': array([ 5,  2,  2,  2, 10, 10,  8, 10,  6,  8,  1,  6], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "%time classifier = grid_svm.fit(text_train, liked_train) # find the best combination from param_svm\n",
    "print(classifier.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       594\n",
      "           1       0.99      0.99      0.99       793\n",
      "\n",
      "    accuracy                           0.99      1387\n",
      "   macro avg       0.99      0.99      0.99      1387\n",
      "weighted avg       0.99      0.99      0.99      1387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(liked_test, classifier.predict(text_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict([\"the vinci code is awesome\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict([\"the vinci code is bad\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32465246735834974"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gaussKernel(x1, x2, sigma):\n",
    "    ss=np.power(sigma,2)\n",
    "    norm= (x1-x2).T.dot(x1-x2)\n",
    "    return np.exp(-norm/(2*ss))\n",
    "x1 = np.array([1, 2, 1])\n",
    "x2 = np.array([0, 4, -1])\n",
    "sigma = 2\n",
    "gaussKernel(x1,x2,sigma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
